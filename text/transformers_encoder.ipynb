{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d70dc045-38a1-4adc-b5d7-3d2a4dba2cb8",
   "metadata": {},
   "source": [
    "# Transformer Encoder Architecture\n",
    "\n",
    "<img src=\"./img/encoder_only.png\" alt=\"encoder_only\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d46628-c99b-4988-bdf6-2d224a9f9e19",
   "metadata": {},
   "source": [
    "Encoder-only transformers simplify the original architecture for scenarios where the primary focus is on understanding and representing the input data, rather than generating sequences, such as text classification, named entity or intent recognition, etc.\n",
    "\n",
    "It consists of multiple encoder layers. Each encoder layer incorporates a multi-headed self-attention mechanism to capture relationships between elements in the sequence, followed by feed-forward layers to map this knowledge into abstract nonlinear representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb05217-51d7-4373-bab0-8c0cc092aaa4",
   "metadata": {},
   "source": [
    "## Pytorch TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddff7957-6c7f-4f21-a291-38c6a2407609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bfb2fb-1f27-4efa-a7b6-1258e7044371",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    'I love this product',\n",
    "    'This is terrible',\n",
    "    'Could be better',\n",
    "    'This is the best',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e6590d-2bec-4be3-a9c1-40ea5634f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90440e89-add2-47dc-a1b0-dadf924cf03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = sample_texts[:3], sample_texts[3:]\n",
    "train_labels, test_labels = labels[:3], labels[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b542a5-56e0-406f-bbc0-f0572c593954",
   "metadata": {},
   "source": [
    "TransformerEncoderLayer:\n",
    "\n",
    "* d_model - influences the model's representational depth\n",
    "* nhead - determines how many word contexts the model can focus on simultaneously, impacting its contextual understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28eba0bf-75e6-44ac-8cd9-e199efeed347",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_size, heads, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=embed_size, nhead=heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b826f-6442-44f8-a953-5d8be8687825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerEncoder(embed_size=512, heads=8, num_layers=3, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54074482-8bac-4b9c-8fd4-dd89b6810eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff319e-a18a-4b16-89ca-270f651766c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(10):\n",
    "    for sentence, label in zip(train_data,train_labels):\n",
    "        # Split the sentences into tokens and stack the embeddings\n",
    "        tokens = sentence.split()\n",
    "        data = torch.stack([token_embeddings[i] for i in tokens], dim=1)\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, torch.tensor([label]))\n",
    "        # Zero the gradients and perform a backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backwards()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880f195-54b2-4092-ac3c-19baf57433ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    # Deactivate the gradient computations and get the sentiment prediction.\n",
    "    with torch.no_grad():\n",
    "        tokens = sentence.split()\n",
    "        data = torch.stack([token_embeddings.get(token, torch.rand((1, 512))) for i in tokens], dim=1)\n",
    "        output = model(data)\n",
    "        predicted = torch.argmax(output, dim=1)\n",
    "    return 'positive' if predicted.item() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1504d0-d804-44fa-b17d-dc3e57b7cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = [\n",
    "    \"the animal didn't cross the street because it was too tired\",\n",
    "    \"the cat sat on the mat\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa50651-38ad-4bdc-90d5-addf4317c5d9",
   "metadata": {},
   "source": [
    "## Feed Forward transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d6358-8da4-4178-a3da-8c3b57f86fb6",
   "metadata": {},
   "source": [
    "Positional encoding and Multi-Head Attention mechanism explained in `./transformers_fundamentals.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1df2378-9524-4534-b0f0-9732fddd5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardTransformation(nn.Module):\n",
    "    \"\"\"\n",
    "    parms: d_model the embedinggs dimensionality\n",
    "    params: d_ff the dimension between linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(\n",
    "            self.relu(\n",
    "                self.fc1(x)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e63d90-4156-4d57-b223-cc685e586679",
   "metadata": {},
   "source": [
    "# Transformer Encoder from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "918175bd-c5ee-4423-8d06-89800f01ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_utils import PositionalEncoder, MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6e84d4-29a9-408b-af5c-af7413270733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForwardTransformation(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.attention(x,x,x,mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d74cc0-76b7-4b66-b141-6e33abbd5c54",
   "metadata": {},
   "source": [
    "Mask is used during the forward pass, concretely in the attention stage to prevent processing of padding tokens.\n",
    "\n",
    "The self-attention mechanism should not look at padded tokens, since they do not contain relevant information for the language task. This is where a padding mask with zeros for padded positions in the sequence, is utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e0c6086-0bfc-431e-924e-4f4bc9efea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.poistional_encoding = PositionalEncoder(d_model, max_seq_length)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.poistional_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c3573-5669-4fe0-88b1-59197e07842f",
   "metadata": {},
   "source": [
    "Transformer head is final output layer designed for specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7fb5f76-6a8e-4560-bd1e-3fa9251cecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, d_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.fc(x)\n",
    "        return nn.functional.log_softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86879c90-2869-4731-8565-54d23772cf7a",
   "metadata": {},
   "source": [
    "## Testing Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd8e2db-25e4-46dd-82ca-016304af49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "vocab_size = 10000\n",
    "batch_size = 8\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "sequence_length = 64\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72cf6b92-5383-4575-b8d6-b4d1840afe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
    "mask = torch.randint(0, 2, (sequence_length, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3849f5c3-d86c-4d39-b95e-63e074cebb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the encoder transformer's body and head\n",
    "encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, sequence_length)\n",
    "classifier = ClassifierHead(d_model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d5c3753-128e-4411-881f-71b603c309d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification outputs for a batch of  8 sequences:\n",
      "tensor([-1.7434, -0.8088, -0.9685], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# The forward pass \n",
    "output = encoder(input_sequence, mask)\n",
    "classification = classifier(output)\n",
    "print(\"Classification outputs for a batch of \", batch_size, \"sequences:\")\n",
    "print(classification[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e92a8-7c03-4cab-936d-efaf1ee203b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
