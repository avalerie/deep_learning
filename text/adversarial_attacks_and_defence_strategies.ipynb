{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5347ac-d26f-4a80-bd24-c33d5dc880ef",
   "metadata": {},
   "source": [
    "# Adversarial attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e767b7-7134-48ee-bc51-b86b141f01a5",
   "metadata": {},
   "source": [
    "What is an Adversarial Attack in AI? \n",
    "\n",
    "It is an attack where the goal is to cause an AI system to make a mistake or misclassification, often through subtle manipulations of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e61ccb0-4d68-45b8-aa75-081c94fc7d14",
   "metadata": {},
   "source": [
    "**Fast Gradient Sign Method (FGSM)**\n",
    "\n",
    "<img src=\"./img/fgsm.png\" alt=\"fgsm.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "It uses precise changes that may go undetected. By exploiting the learning information of a model, it can introduce the tiniest changes to the input, leading the model astray. \n",
    "\n",
    "Example of a spam filter that's usually accurate but gets deceived by a cleverly altered email. Notice the tiny tweak in the word \"love\". To an AI model, this could change the classification. In our real-world example, such alterations can prevent a spammy email from being flagged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15dd93d-997a-4e63-962f-08953b15f67b",
   "metadata": {},
   "source": [
    "**Projected Gradient Descent (PGD)** \n",
    "\n",
    "<img src=\"./img/pgd.png\" alt=\"pgd\" style=\"width: 600px;\"/>\n",
    "\n",
    "It's like the seasoned burglar who picks the lock step by step. \n",
    "\n",
    "It refines its deception across several iterations, ensuring the most effective disturbance. Example of fake news detector, PGD could subtly adjust an article's phrasing over and over until the AI is convinced of its authenticity. Here, likely becomes set to, altering the prediction confidence. If this were a fake news detector, such iterative tweaks could confuse AI's judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e373847-2fa0-4c79-8ed3-14b96d06009f",
   "metadata": {},
   "source": [
    "**The Carlini & Wagner (C&W) attack**\n",
    "\n",
    "<img src=\"./img/cw.png\" alt=\"cw\" style=\"width: 600px;\"/>\n",
    "\n",
    "It's like the mastermind spy who leaves no trace. \n",
    "\n",
    "By focusing on optimizing a loss function, it ensures that the modifications are not just deceptive to the AI but virtually undetectable to us. Consider an AI-driven stock trading system; C&W could tweak a financial transcript subtly, potentially causing erroneous investments. The addition of \"somewhat\" can change the sentiment and context, especially if used in critical financial or medical reports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a24bf-ce1f-4e14-be8a-22859043cfe7",
   "metadata": {},
   "source": [
    "**Defence strategies:**\n",
    "\n",
    "* Model ensembling\n",
    "* Data Augmentation\n",
    "* Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e60f5d-d663-43f9-8261-0dd70ede139f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
